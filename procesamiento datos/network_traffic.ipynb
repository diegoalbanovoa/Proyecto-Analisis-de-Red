{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project :Network traffic analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data traffic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset and load it into dataframe\n",
    "data = \"resources/output.csv\"\n",
    "df = pd.read_csv(data, delimiter=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: 7, Rows: 585462\n",
      "Dataset dimension with no null or bad data \n",
      "Columns: 7, Rows: 585395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataset dimension\n",
    "shape = df.shape\n",
    "print(f\"Columns: {shape[1]}, Rows: {shape[0]}\")\n",
    "\n",
    "#Remove null data or clean the dataset of garbage elements\n",
    "df = df.dropna()\n",
    "print(f\"Dataset dimension with no null or bad data \\nColumns: {df.shape[1]}, Rows: {df.shape[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 585395 entries, 0 to 585461\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   No.          585395 non-null  int64  \n",
      " 1   Time         585395 non-null  float64\n",
      " 2   Source       585395 non-null  object \n",
      " 3   Destination  585395 non-null  object \n",
      " 4   Protocol     585395 non-null  object \n",
      " 5   Length       585395 non-null  int64  \n",
      " 6   Info         585395 non-null  object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 35.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Data frame summary\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the 'Protocol' \n",
      "['ICMP' 'IPv4' 'DHCPv6' 'ICMPv6' 'ARP' 'DNS' 'TCP' 'SSLv3' 'HTTP' 'TELNET'\n",
      " 'UDP' 'FTP' 'Messenger' 'MANOLITO' 'THRIFT' 'Gnutella' 'HTTP/XML'\n",
      " 'IGMPv2' 'IGMPv1' 'RGMP' 'STP' 'CDP' 'Syslog' 'PPP LCP' 'L2TP' 'TLSv1'\n",
      " 'OCSP' 'RADIUS' 'WSP' 'DHCP' 'PPPoED' 'PPP CHAP' 'PPP IPCP' 'PPP IPV6CP'\n",
      " 'NTP' 'SIP' 'PPP PAP' 'SIP/SDP' 'RTP' 'Portmap' 'MOUNT' 'NFS' 'RPC'\n",
      " 'PTPv2' 'SMB2' 'SMTP' 'SMTP/IMF' 'BROWSER' 'SNMP' 'UFTP' 'IGMPv3'\n",
      " 'FTP-DATA' 'MDNS' 'TLSv1.2' 'SSDP' 'TLSv1.3' 'QUIC' 'HTTP/JSON'\n",
      " 'PKIX-CRL' 'XMPP/XML' 'LLMNR' 'NNTP' 'SSL' 'SSLv2' 'NBNS']\n"
     ]
    }
   ],
   "source": [
    "# unique values of the 'Protocol' column in the DataFrame df.\n",
    "print(f\"Values of the 'Protocol' \\n{df['Protocol'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "from pylab import rcParams\n",
    " \n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    " \n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Consolidation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
