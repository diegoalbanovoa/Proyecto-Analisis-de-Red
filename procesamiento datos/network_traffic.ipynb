{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project :Network traffic analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join different network traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo final guardado en:  ../Dataset Crudo Proceso de Clasificación/output.csv\n"
     ]
    }
   ],
   "source": [
    "# Define la ruta de los archivos CSV en crudo\n",
    "raw_data_path = r\"../Dataset en Crudo\"\n",
    "\n",
    "# Busca todos los archivos CSV en la ruta\n",
    "csv_files = [f for f in os.listdir(raw_data_path) if f.endswith('.csv')]\n",
    "\n",
    "# Crea una lista vacía para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Itera sobre cada archivo CSV y agrega su DataFrame a la lista\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(raw_data_path, csv_file)\n",
    "    df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatena todos los DataFrames en uno solo\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Define la ruta y el nombre del archivo final\n",
    "output_path = r\"../Dataset Crudo Proceso de Clasificación/output.csv\"\n",
    "\n",
    "# Guarda el archivo final en la ruta especificada\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Archivo final guardado en: \", output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data traffic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset and load it into dataframe\n",
    "data = r\"../Dataset Crudo Proceso de Clasificación/output.csv\"\n",
    "df = pd.read_csv(data, delimiter=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: 7, Rows: 585462\n",
      "Dataset dimension with no null or bad data \n",
      "Columns: 7, Rows: 585395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataset dimension\n",
    "shape = df.shape\n",
    "print(f\"Columns: {shape[1]}, Rows: {shape[0]}\")\n",
    "\n",
    "#Remove null data or clean the dataset of garbage elements\n",
    "df = df.dropna()\n",
    "print(f\"Dataset dimension with no null or bad data \\nColumns: {df.shape[1]}, Rows: {df.shape[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 585395 entries, 0 to 585461\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   No.          585395 non-null  int64  \n",
      " 1   Time         585395 non-null  float64\n",
      " 2   Source       585395 non-null  object \n",
      " 3   Destination  585395 non-null  object \n",
      " 4   Protocol     585395 non-null  object \n",
      " 5   Length       585395 non-null  int64  \n",
      " 6   Info         585395 non-null  object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 35.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Data frame summary\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the 'Protocol' \n",
      "['ICMP' 'IPv4' 'DHCPv6' 'ICMPv6' 'ARP' 'DNS' 'TCP' 'SSLv3' 'HTTP' 'TELNET'\n",
      " 'UDP' 'FTP' 'Messenger' 'MANOLITO' 'THRIFT' 'Gnutella' 'HTTP/XML'\n",
      " 'IGMPv2' 'IGMPv1' 'RGMP' 'STP' 'CDP' 'Syslog' 'PPP LCP' 'L2TP' 'TLSv1'\n",
      " 'OCSP' 'RADIUS' 'WSP' 'DHCP' 'PPPoED' 'PPP CHAP' 'PPP IPCP' 'PPP IPV6CP'\n",
      " 'NTP' 'SIP' 'PPP PAP' 'SIP/SDP' 'RTP' 'Portmap' 'MOUNT' 'NFS' 'RPC'\n",
      " 'PTPv2' 'SMB2' 'SMTP' 'SMTP/IMF' 'BROWSER' 'SNMP' 'UFTP' 'IGMPv3'\n",
      " 'FTP-DATA' 'MDNS' 'TLSv1.2' 'SSDP' 'TLSv1.3' 'QUIC' 'HTTP/JSON'\n",
      " 'PKIX-CRL' 'XMPP/XML' 'LLMNR' 'NNTP' 'SSL' 'SSLv2' 'NBNS']\n"
     ]
    }
   ],
   "source": [
    "# unique values of the 'Protocol' column in the DataFrame df.\n",
    "print(f\"Values of the 'Protocol' \\n{df['Protocol'].unique()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la ruta del archivo CSV y la carpeta para guardar los nuevos archivos\n",
    "csv_path = r'../Dataset Crudo Proceso de Clasificación/output.csv'\n",
    "folder_path = r'../Dataset Proceso de Clasificación'\n",
    "\n",
    "# Lee el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Elimina la columna \"No.\"\n",
    "df = df.drop('No.', axis=1)\n",
    "\n",
    "# Crea la carpeta si no existe\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Crea un diccionario para almacenar los DataFrames de cada protocolo\n",
    "protocol_dfs = {}\n",
    "\n",
    "# Filtra los resultados del conteo por los protocolos de aplicación conocidos\n",
    "app_protocols = ['HTTP', 'DNS', 'TCP', 'FTP', 'ICMP', 'UDP']\n",
    "for protocol in app_protocols:\n",
    "    # Verifica si hay suficientes filas en el DataFrame para el protocolo actual\n",
    "    if (df['Protocol'] == protocol).sum() <= 700:\n",
    "        data = (df['Protocol'] == protocol).sum()\n",
    "        print(data)\n",
    "        print(f\"No hay suficientes filas para el protocolo {protocol}\")\n",
    "        continue\n",
    "    \n",
    "    # Selecciona 700 filas aleatorias del DataFrame para cada protocolo\n",
    "    random.seed(42)\n",
    "    protocol_df = df.loc[df['Protocol'] == protocol].sample(n=700, random_state=42)\n",
    "    protocol_dfs[protocol] = protocol_df\n",
    "\n",
    "# Guarda cada DataFrame en un archivo CSV separado\n",
    "for protocol, protocol_df in protocol_dfs.items():\n",
    "    filename = f'{protocol.lower()}_output.csv'\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    protocol_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la ruta de la carpeta que contiene los archivos CSV\n",
    "folder_path = r'../Dataset Proceso de Clasificación'\n",
    "\n",
    "# Crea una lista vacía para almacenar los DataFrames de cada archivo CSV\n",
    "dfs = []\n",
    "\n",
    "# Lee cada archivo CSV en un DataFrame y agrégalo a la lista\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatena los DataFrames en uno solo\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Mezcla las filas del DataFrame de forma pseudoaleatoria\n",
    "random.seed(42)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Guarda el DataFrame mezclado en un archivo CSV\n",
    "mixed_csv_path = r'C:\\Users\\diego\\Videos\\Proyecto Analisis de Red\\Proyecto-Analisis-de-Red\\Dataset Analisis de redes\\dataset.csv'\n",
    "df.to_csv(mixed_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
